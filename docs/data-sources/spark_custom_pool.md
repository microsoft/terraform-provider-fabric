---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "fabric_spark_custom_pool Data Source - terraform-provider-fabric"
subcategory: ""
description: |-
  The Spark Custom Pool data-source allows you to retrieve details about a Fabric Spark Custom Pool https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools.
  -> This data-source supports Service Principal authentication.
  ~> This data-source is in preview. To access it, you must explicitly enable the preview mode in the provider level configuration.
---

# fabric_spark_custom_pool (Data Source)

The Spark Custom Pool data-source allows you to retrieve details about a Fabric [Spark Custom Pool](https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools).

-> This data-source supports Service Principal authentication.

~> This data-source is in **preview**. To access it, you must explicitly enable the `preview` mode in the provider level configuration.

## Example Usage

```terraform
data "fabric_spark_custom_pool" "example_by_id" {
  id           = "11111111-1111-1111-1111-111111111111"
  workspace_id = "00000000-0000-0000-0000-000000000000"
}

data "fabric_spark_custom_pool" "example_by_name" {
  name         = "example"
  workspace_id = "00000000-0000-0000-0000-000000000000"
}

# This is an invalid data source
# Do not specify id and name in the same data source block
# data "fabric_spark_custom_pool" "example" {
#   name = "example"
#   id = "11111111-1111-1111-1111-111111111111"
#   workspace_id = "00000000-0000-0000-0000-000000000000"
# }
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `workspace_id` (String) The Workspace ID.

### Optional

- `id` (String) The Spark Custom Pool ID.
- `name` (String) The Spark Custom Pool ID. String length must be at most 64. The name must contain only letters, numbers, dashes, underscores and spaces.
- `timeouts` (Attributes) (see [below for nested schema](#nestedatt--timeouts))

### Read-Only

- `auto_scale` (Attributes) Auto-scale properties. (see [below for nested schema](#nestedatt--auto_scale))
- `dynamic_executor_allocation` (Attributes) Dynamic Executor Allocation properties. (see [below for nested schema](#nestedatt--dynamic_executor_allocation))
- `node_family` (String) The Node family. Value must be one of : `MemoryOptimized`.
- `node_size` (String) The Node size. Value must be one of : `Large`, `Medium`, `Small`, `XLarge`, `XXLarge`.
- `type` (String) The Spark Custom Pool type. Value must be one of : `Capacity`, `Workspace`.

<a id="nestedatt--timeouts"></a>

### Nested Schema for `timeouts`

Optional:

- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

<a id="nestedatt--auto_scale"></a>

### Nested Schema for `auto_scale`

Read-Only:

- `enabled` (Boolean) The status of the auto scale: `false` - Disabled, `true` - Enabled.
- `max_node_count` (Number) The maximum node count.
- `min_node_count` (Number) The minimum node count.

<a id="nestedatt--dynamic_executor_allocation"></a>

### Nested Schema for `dynamic_executor_allocation`

Read-Only:

- `enabled` (Boolean) The status of the dynamic executor allocation: `false` - Disabled, `true` - Enabled.
- `max_executors` (Number) The maximum executors.
- `min_executors` (Number) The minimum executors.
