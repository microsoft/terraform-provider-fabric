---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "fabric_spark_job_definitions Data Source - terraform-provider-fabric"
subcategory: ""
description: |-
  The Spark Job Definition data-source allows you to retrieve details about a Fabric Spark Job Definition https://learn.microsoft.com/fabric/data-engineering/spark-job-definition.
  -> This data-source supports Service Principal authentication.
---

# fabric_spark_job_definitions (Data Source)

The Spark Job Definition data-source allows you to retrieve details about a Fabric [Spark Job Definition](https://learn.microsoft.com/fabric/data-engineering/spark-job-definition).

-> This data-source supports Service Principal authentication.

## Example Usage

```terraform
data "fabric_spark_job_definitions" "example" {
  workspace_id = "00000000-0000-0000-0000-000000000000"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `workspace_id` (String) The Workspace ID.

### Optional

- `timeouts` (Attributes) (see [below for nested schema](#nestedatt--timeouts))

### Read-Only

- `values` (Attributes Set) The set of Spark Job Definitions. (see [below for nested schema](#nestedatt--values))

<a id="nestedatt--timeouts"></a>

### Nested Schema for `timeouts`

Optional:

- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

<a id="nestedatt--values"></a>

### Nested Schema for `values`

Read-Only:

- `description` (String) The Spark Job Definition description.
- `display_name` (String) The Spark Job Definition display name.
- `id` (String) The Spark Job Definition ID.
- `properties` (Attributes) The Spark Job Definition properties. (see [below for nested schema](#nestedatt--values--properties))
- `workspace_id` (String) The Workspace ID.

<a id="nestedatt--values--properties"></a>

### Nested Schema for `values.properties`

Read-Only:

- `onelake_root_path` (String) OneLake path to the Spark Job Definition root directory.
