---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "fabric_spark_custom_pool Resource - terraform-provider-fabric"
subcategory: ""
description: |-
  Manage a Fabric Spark Custom Pool.
  See Spark Custom Pool https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools for more information.
  -> This item supports Service Principal authentication.
---

# fabric_spark_custom_pool (Resource)

Manage a Fabric Spark Custom Pool.

See [Spark Custom Pool](https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools) for more information.

-> This item supports Service Principal authentication.

## Example Usage

```terraform
resource "fabric_spark_custom_pool" "example" {
  workspace_id = "00000000-0000-0000-0000-000000000000"
  name         = "example"
  node_family  = "MemoryOptimized"
  node_size    = "Small"
  type         = "Workspace"

  auto_scale = {
    enabled        = true
    min_node_count = 1
    max_node_count = 3
  }

  dynamic_executor_allocation = {
    enabled       = true
    min_executors = 1
    max_executors = 2
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `auto_scale` (Attributes) Auto-scale properties. (see [below for nested schema](#nestedatt--auto_scale))
- `dynamic_executor_allocation` (Attributes) Dynamic Executor Allocation properties. (see [below for nested schema](#nestedatt--dynamic_executor_allocation))
- `name` (String) The Spark Custom Pool name.
- `node_family` (String) The Node family. Accepted values: `MemoryOptimized`.
- `node_size` (String) The Node size. Accepted values: `Large`, `Medium`, `Small`, `XLarge`, `XXLarge`.
- `type` (String) The Spark Custom Pool type. Accepted values: `Workspace`.
- `workspace_id` (String) The Workspace ID.

### Optional

- `timeouts` (Attributes) (see [below for nested schema](#nestedatt--timeouts))

### Read-Only

- `id` (String) The Spark Custom Pool ID.

<a id="nestedatt--auto_scale"></a>

### Nested Schema for `auto_scale`

Required:

- `enabled` (Boolean) The status of the auto scale. Accepted values: `false` - Disabled, `true` - Enabled.
- `max_node_count` (Number) The maximum node count.
- `min_node_count` (Number) The minimum node count.

<a id="nestedatt--dynamic_executor_allocation"></a>

### Nested Schema for `dynamic_executor_allocation`

Required:

- `enabled` (Boolean) The status of the dynamic executor allocation. Accepted values: `false` - Disabled, `true` - Enabled.

Optional:

- `max_executors` (Number) The maximum executors.
- `min_executors` (Number) The minimum executors.

<a id="nestedatt--timeouts"></a>

### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Read operations occur during any refresh or planning operation when refresh is enabled.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

## Import

Import is supported using the following syntax:

```shell
# terraform import fabric_spark_custom_pool.example "<WorkspaceID>/<PoolID>"
terraform import fabric_spark_custom_pool.example "00000000-0000-0000-0000-000000000000/11111111-1111-1111-1111-111111111111"
```
