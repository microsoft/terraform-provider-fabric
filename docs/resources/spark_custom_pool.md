---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "fabric_spark_custom_pool Resource - terraform-provider-fabric"
subcategory: ""
description: |-
  The Spark Custom Pool resource allows you to manage a Fabric Spark Custom Pool https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools.
  -> This resource supports Service Principal authentication.
  ~> This resource is in preview. To access it, you must explicitly enable the preview mode in the provider level configuration.
---

# fabric_spark_custom_pool (Resource)

The Spark Custom Pool resource allows you to manage a Fabric [Spark Custom Pool](https://learn.microsoft.com/fabric/data-engineering/create-custom-spark-pools).

-> This resource supports Service Principal authentication.

~> This resource is in **preview**. To access it, you must explicitly enable the `preview` mode in the provider level configuration.

## Example Usage

```terraform
resource "fabric_spark_custom_pool" "example" {
  workspace_id = "00000000-0000-0000-0000-000000000000"
  name         = "example"
  node_family  = "MemoryOptimized"
  node_size    = "Small"
  type         = "Workspace"

  auto_scale = {
    enabled        = true
    min_node_count = 1
    max_node_count = 3
  }

  dynamic_executor_allocation = {
    enabled       = true
    min_executors = 1
    max_executors = 2
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `auto_scale` (Attributes) Auto-scale properties. (see [below for nested schema](#nestedatt--auto_scale))
- `dynamic_executor_allocation` (Attributes) Dynamic Executor Allocation properties. (see [below for nested schema](#nestedatt--dynamic_executor_allocation))
- `name` (String) The Spark Custom Pool ID. String length must be at most 64. The name must contain only letters, numbers, dashes, underscores and spaces.Value must not be one of : .
- `node_family` (String) The Node family. Value must be one of : `MemoryOptimized`.
- `node_size` (String) The Node size. Value must be one of : `Large`, `Medium`, `Small`, `XLarge`, `XXLarge`.
- `type` (String) The Spark Custom Pool type. Value must be one of : `Workspace`.
- `workspace_id` (String) <i style="color:red;font-weight: bold">(ForceNew)</i> The Workspace ID.

### Optional

- `timeouts` (Attributes) (see [below for nested schema](#nestedatt--timeouts))

### Read-Only

- `id` (String) The Spark Custom Pool ID.

<a id="nestedatt--auto_scale"></a>
### Nested Schema for `auto_scale`

Required:

- `enabled` (Boolean) The status of the auto scale: `false` - Disabled, `true` - Enabled.
- `max_node_count` (Number) The maximum node count.
- `min_node_count` (Number) The minimum node count.


<a id="nestedatt--dynamic_executor_allocation"></a>
### Nested Schema for `dynamic_executor_allocation`

Required:

- `enabled` (Boolean) The status of the dynamic executor allocation: `false` - Disabled, `true` - Enabled.

Optional:

- `max_executors` (Number) The maximum executors. If the value of [`dynamic_executor_allocation.enabled`](#dynamic_executor_allocation.enabled) attribute is `false` this attribute is **NULL**. If the value of [`dynamic_executor_allocation.enabled`](#dynamic_executor_allocation.enabled) attribute is `true` this attribute is **REQUIRED**.
- `min_executors` (Number) The minimum executors. If the value of [`dynamic_executor_allocation.enabled`](#dynamic_executor_allocation.enabled) attribute is `false` this attribute is **NULL**. If the value of [`dynamic_executor_allocation.enabled`](#dynamic_executor_allocation.enabled) attribute is `true` this attribute is **REQUIRED**.


<a id="nestedatt--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Read operations occur during any refresh or planning operation when refresh is enabled.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
# terraform import fabric_spark_custom_pool.example "<WorkspaceID>/<PoolID>"
terraform import fabric_spark_custom_pool.example "00000000-0000-0000-0000-000000000000/11111111-1111-1111-1111-111111111111"
```
